actor_entropy,actor_loss,actor_target_entropy,alpha_loss,alpha_value,batch_reward,critic_loss,step
0.31498666291870175,-1.6903886197553948,-0.04999999999999823,0.03498381016677013,0.09679961567055902,1.001600334584713,0.04644919804448727,1000
0.40876371987536547,-2.684972042322159,-0.04999999999999823,0.04034346595546231,0.0879584934429065,1.0016127275824547,0.005363983576418832,2000
